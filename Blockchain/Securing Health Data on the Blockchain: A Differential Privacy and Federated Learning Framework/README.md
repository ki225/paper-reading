# 文章閱讀: Securing Health Data on the Blockchain: A Differential Privacy and Federated Learning Framework

- 原文: https://arxiv.org/abs/2405.11580
- 關鍵字: smart cities; cyber security; Internet of Things; cyber-physical systems; zero-trust; ABAC;
blockchain; IPFS


# Introduction
FL並不免受隱私威脅，例如推斷攻擊和連結攻擊，惡意行為者可能會從共享的模型更新中重建個別數據點

為了進一步減輕這些隱私漏洞，已提出差分隱私（DP）作為一種堅實的技術，通過向數據或模型參數引入受控噪聲來提供正式的隱私保證。然而，隨意應用噪聲可能會顯著降低模型的效用，這使得有效平衡隱私和準確性變得具有挑戰性。

最近在個性化FL方面的進展，如動態個性化和自適應噪聲分佈策略，已顯示出在解決數據異質性和隱私保護挑戰方面的潛力，通過自適應確定本地模型的個性化和共享組件，並應用不同的噪聲級別以增強模型的性能和穩健性[11]。然而，這些方法仍然面臨全面的隱私保護、安全性和數據完整性的限制。

為了進一步增強基於物聯網系統的健康數據的安全性和隱私，區塊鏈技術作為一種有前景的解決方案應運而生，為安全和透明的數據管理提供了可能，促成了基於區塊鏈的物聯網（BIoT）系統的出現。儘管取得了這些進展，但在有效整合FL、DP和區塊鏈技術以提供全面解決方案方面仍然存在挑戰，這些解決方案需要同時考慮隱私、安全性和數據完整性，並平衡效用和隱私。

# PRELIMINARIES 先備知識
## 聯邦學習

1) 問題定式：考慮一組K個客戶端，每個客戶端都有自己的本地數據集$D_k$，其中k ∈ 1, . . . , K。目標是學習一個全局模型w，使其最小化以下目標函數：
$$\min_{w} f(w) = \sum_{k=1}^{K} \frac{n_k}{n} F_k(w), \tag{1}$$
其中 $n_k = |D_k|$ 是第k個客戶端數據集中的數據樣本數，$n = \sum_{k=1}^{K} n_k$ 是所有客戶端的數據樣本總數，$F_k(w)$ 是第k個客戶端的本地目標函數，定義為：
$$
F_k(w) = \frac{1}{N_k} \sum_{i \in D_k} \ell(w, x_i, y_i), \tag{2}
$$
其中 $\ell(w, x_i, y_i)$ 是第k個客戶端數據集中第i個數據樣本 $(x_i, y_i)$ 的損失函數。

2) 聯邦平均（FedAvg）：FedAvg 是FL環境中訓練模型的流行算法。該算法以回合方式進行，每回合t中選擇一個客戶端子集 $S_t$ 參與訓練。每個被選中的客戶端 $k \in S_t$ 在其數據集 $D_k$ 上進行固定次數的本地訓練並更新其本地模型 $w^t_k$。然後，客戶端將其更新的本地模型發送給中央伺服器，中央伺服器將其聚合以更新全局模型 $w^{t+1}$，計算公式如下：
$$
w^{t+1} = \sum_{k \in S_t} \frac{n_k}{n_{S_t}} w^t_k, \tag{3}
$$
其中 $n_{S_t} = \sum_{k \in S_t} n_k$ 是回合t中選擇的客戶端的數據樣本總數。然後，更新後的全局模型將分發回客戶端以進行下一回合的本地訓練。

## 差分隱私

差分隱私（DP）是一個數學框架，用於量化在操作敏感數據的算法所提供的隱私保證。DP確保算法的輸出不會顯著依賴於任何單一數據點，從而限制隱私洩露的風險。

1) 定義：如果一個隨機算法M對於任何兩個相鄰數據集D和D′（最多在一個數據點上有所不同），以及對於任何輸出子集 $S \subseteq \text{Range}(M)$，滿足以下條件，則稱其為(ϵ, δ)-差分隱私：
$$
\Pr[M(D) \in S] \leq e^{ϵ} \cdot \Pr[M(D′) \in S] + δ, \tag{4}
$$
其中 ϵ > 0 是隱私預算，控制隱私保護的級別，$δ \in [0, 1]$ 是一個小常數，允許出現輕微的隱私違規。較小的\( ϵ \)提供更強的隱私保證，而較大的\( ϵ \)則允許輸出中有更多的實用性。

2) 拉普拉斯機制：拉普拉斯機制是一種常用的技術，用於實現ϵ-DP，該技術涉及向應用於數據集D的函數f的輸出添加拉普拉斯噪聲。噪聲的調整基於函數的靈敏度，表示為 $\Delta f$，定義為應用於任何兩個相鄰數據集D和D′時，函數輸出可能的最大變化：
$$\Delta f = \max_{D,D′} |f(D) − f(D′)|_1. \tag{5}$$
為了實現 ϵ-DP，拉普拉斯機制（Laplace Mechanism）在函數 f 的輸出中加入來自拉普拉斯分佈的噪聲，其比例參數為 $b = \frac{\Delta f}{\epsilon}$：
$$
M(D) = f(D) + \text{Lap} \left( \frac{\Delta f}{\epsilon} \right) \tag{6}
$$
其中，Lap(b) 表示從均值為 0 且比例參數為 b 的拉普拉斯分佈中抽取的隨機變量。

3) 高斯機制（Gaussian Mechanism）：高斯機制是另一種實現 (ϵ, δ)-DP 的技術，它涉及將高斯噪聲添加到應用於數據集 D 的函數 f 的輸出中。噪聲根據函數的 L2 敏感性進行調整，記作 $\Delta^2 f$，其定義為當函數應用於任兩個相鄰的數據集 D 和 D' 時，函數輸出的最大 L2-範數變化：
$$
\Delta_2 f = \max_{D, D'} |f(D) - f(D')|^2 \tag{7}
$$
為了實現 (ϵ, δ)-DP，高斯機制在 f 的輸出中加入來自高斯分佈的噪聲，其標準差為 $\sigma = \frac{\Delta_2 f \sqrt{2 \ln(1.25/\delta)}}{\epsilon}$ 因此， 
$$
M(D) = f(D) + N(0, \sigma^2) \tag{8}
$$
其中，$N(0, \sigma^2)$ 表示從均值為 0 和方差為 $\sigma^2$ 的高斯分佈中抽取的隨機變量。

## 區塊鏈技術 
區塊鏈是一種去中心化、不可變更的分類帳技術，能夠安全且透明地記錄交易，而無需中央權威的介入。作者的框架利用以太坊（Ethereum）區塊鏈平台，該平台支持智能合約並允許開發去中心化應用程序（DApps）。

1) 以太坊與智能合約：以太坊是一個開源的、基於區塊鏈的分散式計算平台，能夠部署和執行智能合約。智能合約是自我執行的合約，其協議條款直接寫入代碼中。這些合約部署在以太坊區塊鏈上，並可以通過交易進行互動。
作者的框架使用智能合約來促進本地模型更新的安全聚合和存儲。智能合約的代碼使用 Solidity 編寫，這是一種專門為在以太坊區塊鏈上實現智能合約而設計的高級編程語言。

2) Truffle 框架：Truffle 是一個流行的以太坊開發框架，提供一套用於編寫、測試和部署智能合約的工具。它通過提供開發環境、測試框架和部署管道，簡化了智能合約的構建和管理過程。
作者利用 Truffle 編譯、測試和部署我們的智能合約到以太坊區塊鏈。Truffle 也能夠整合我們的框架與以太坊生態系統中的其他工具和庫，例如 Web3.js，以便從客戶端與區塊鏈互動。

3) 共識機制：截至2022年9月，以太坊已通過以太坊2.0升級（也稱為「合併」）從工作量證明（PoW）轉向權益證明（PoS）共識機制。在 PoS 中，驗證者根據他們抵押的加密貨幣數量來選擇創建新區塊。這一轉變旨在提高以太坊網絡的可擴展性、安全性和能源效率。
然而，出於本地開發和測試的目的，我們使用 Truffle 框架與模擬的以太坊區塊鏈（如 Ganache），該區塊鏈仍然採用基於 PoW 的共識機制。這樣可以與現有的開發工具兼容，並提供模擬環境以測試我們的智能合約，然後再將其部署到主以太坊網絡上。
在將智能合約部署到主以太坊網絡時，它們將受 PoS 共識機制的約束，確保存儲的模型更新的安全性和不可變性。

4) 燃料費和交易成本：在以太坊中，燃料費是一個單位，用於衡量執行交易和智能合約操作所需的計算努力。每筆交易和智能合約操作消耗一定量的燃料費，由發起交易的用戶用以太幣（Ether，ETH）支付，這是以太坊的原生加密貨幣。
交易的總成本（Ct）可以計算為：
$$
C_t = G_t \times G_p 
$$
其中 $G_t$ 是交易消耗的總燃料費，而 $G_p$ 是用戶設置的燃料費價格，通常以 Gwei 為單位（1 Gwei = $10^{-9}$ ETH）。
在作者的框架中，燃料消耗和交易成本是評估區塊鏈整合效率和實用性的主要考量因素。

## 動態個性化和自適應噪聲分佈 
在提出的框架中，採用中引入的動態個性化和自適應噪聲分佈策略，以增強聯邦學習過程的靈活性和穩健性。

1) 動態個性化：動態個性化旨在根據每個參數在捕獲本地數據特徵中的重要性，自適應地確定本地模型的個性化和共享組件。層級重要性度量是使用費雪信息矩陣（Fisher Information Matrix, FIM）計算的，其定義為：
$$
F_k = E_{(x,y) \sim D_k} \left[ \nabla_{w_k} \log p(y|x, w_k) \nabla_{w_k} \log p(y|x, w_k)^\top \right] \tag{10} 
$$
其中  $p(y|x, w_k)$ 是給定輸入 x 和模型參數 $w_k$ 的標籤 y  的預測概率。客戶端 $C_k$ 第 l 層的層級重要性度量計算為：
$$
s_{k,l} = \frac{\sum_{i \in I_l} [F_k]_{i,i}}{\sum_{i=1}^d [F_k]_{i,i}} \tag{11}
$$

其中 \( $I_l$ \) 是對應於第 \( l \) 層參數的索引集合。具有較高重要性度量的參數被保留為個性化組件，而其餘參數則由從區塊鏈網絡接收的全局參數替換。

**2) 自適應噪聲分佈**：自適應噪聲分佈被用來增強模型對差分隱私中裁剪操作的穩健性。根據重要性度量將本地模型更新分為個性化和共享參數。客戶端 \( $C_k$ \) 的帶噪音本地模型更新計算為：

$$
\tilde{w}_k = w_k + [n_u; n_v] \tag{12}
$$

其中 \( $n_u \sim N(0, \sigma_u^2 I_{d_u})$ \) 和 \( $n_v \sim N(0, \sigma_v^2 I_{d_v})$ \) 是具有不同方差 \( $\sigma_u^2$ \) 和 \( $\sigma_v^2$ \) 的高斯噪聲向量，分別用於個性化和共享參數。方差根據隱私預算 \( $\epsilon$ \) 和裁剪閾值 \( C \) 來確定。個性化參數接收較少的噪聲以保護其本地信息，而共享參數則接收更多的噪聲，以符合裁剪閾值。

這些動態個性化和自適應噪聲分佈策略使我們的框架能夠在聯邦學習和差分隱私的背景下有效地平衡隱私保護和模型效用。



# PROPOSED MODEL
## System Architecture
主要由(1) IoT 設備，(2) FL 客戶端，和 (3) 區塊鏈網路 組成

![image](https://hackmd.io/_uploads/rJ6zZ7rb1g.png)


1) **IoT 設備**：IoT 設備，如可穿戴設備、智能手機和醫療傳感器，從個體收集與健康相關的數據。這些設備負責數據的預處理，包括清理、標準化和特徵提取任務。預處理後的數據會安全地傳輸到與設備相關的相應 FL 客戶端。

2) **FL 客戶端**：FL 客戶端是聯邦學習過程中的參與者，每個客戶端持有一個包含其所屬 IoT 設備收集的預處理健康數據的本地數據集。我們的模型考慮一組 K 個 FL 客戶端，記作 \( C_1, \ldots, C_K \)，其中每個客戶端 \( C_k \) 擁有一個本地數據集 \( D_k \)。FL 客戶端負責以下任務：

    - **本地模型訓練**：每個 FL 客戶端 \( C_k \) 使用預定義的學習算法（例如，隨機梯度下降）在其本地數據集 \( D_k \) 上訓練本地模型 \( w_k \)。本地訓練過程旨在最小化公式 (2) 中的本地目標函數 \( F_k(w_k) \)，通常定義為本地數據集的平均損失。

    - **動態個性化**：我們採用 [11] 中提出的基於 Fisher 信息的方法來實現靈活和自適應的個性化策略。每個客戶端計算其本地模型參數的層級 Fisher 信息，反映每個參數在捕捉本地數據特徵中的重要性。具有較高 Fisher 信息的參數被保留為個性化組件，而其餘參數則由從區塊鏈網絡接收的全局參數替換。這種動態個性化方法確保模型適應客戶端之間異質數據分佈，同時最小化 DP 噪聲對個性化參數的影響。

    - **自適應噪聲分佈**：為了增強模型對 DP 中裁剪操作的穩健性，我們採用來自 [11] 的自適應噪聲分佈策略。根據 Fisher 信息，將本地模型更新分為個性化和共享參數。對這兩組參數添加不同級別的高斯噪聲，其中個性化參數接收較少的噪聲以保護其本地信息，而共享參數則接收更多的噪聲，以符合裁剪閾值。這種自適應噪聲分佈方法平衡了隱私保護和模型效用。

    - **模型更新共享**：在應用動態個性化和自適應噪聲分佈後，FL 客戶端將其本地模型更新共享給區塊鏈網絡進行聚合。共享過程使用加密技術（如數字簽名和加密）進行安全性處理，以確保共享更新的完整性和保密性。

3) **區塊鏈網絡**：區塊鏈網絡作為一個安全和透明的平台，用於聚合本地模型更新並維護聯邦學習過程的防篡改記錄。區塊鏈網絡由一組節點組成，這些節點可以是 FL 客戶端本身或負責共識和區塊生成的專用節點。我們模型中區塊鏈網絡的主要功能包括：

    - **模型聚合**：區塊鏈網絡收集來自 FL 客戶端的經 DP 保護的本地模型更新，並執行安全聚合以獲得全局模型更新。聚合過程通常基於本地更新的加權平均，其中權重由每個客戶端的本地數據集大小決定。

    - **模型更新驗證**：區塊鏈網絡驗證來自 FL 客戶端的本地模型更新的完整性和真實性。這一驗證過程確保合法的客戶端生成更新，並且在傳輸過程中未遭篡改。數字簽名和共識機制（如工作量證明或股權證明）被用來實現安全驗證。

    - **模型更新存儲**：驗證後的本地模型更新和聚合的全局模型更新被存儲在區塊鏈上作為交易。每筆交易包括模型更新數據、時間戳和前一區塊的加密哈希，形成一個不可變和可審計的聯邦學習過程記錄。存儲的模型更新可以供授權方訪問，以進行驗證和分析。

## Federated Learning Algorithm

![image](https://hackmd.io/_uploads/B1W0bmS-yl.png)

```py
# 算法 1: 帶有動態個性化、適應性噪聲分佈和區塊鏈的聯邦學習
def federated_learning(Eg, El, K, epsilon, C, D):
    # 輸入: 全局訓練週期 Eg, 本地訓練週期 El, 客戶端數量 K,
    # 隱私預算 ϵ, 剪裁閾值 C, 本地數據集 D = D1, ..., DK
    # 輸出: 全局模型 wEg
    
    # 1. 初始化全局模型 w0
    w = initialize_global_model()

    # 2. 對於每個全局週期 t 從 1 到 Eg
    for t in range(1, Eg + 1):
        # 3. 對於每個客戶端 Ck 進行並行處理
        local_updates = []  # 儲存本地更新
        for k in range(1, K + 1):
            # 4. 從區塊鏈網絡接收全局模型 wt−1
            w_prev = receive_global_model_from_blockchain(t - 1)

            # 5. 使用 Eq. (10) 和 (11) 計算逐層重要性度量 sk,l
            s = compute_importance_measures(w_prev, D[k - 1])

            # 6. 根據 sk,l 和閾值 τ 構建個性化掩碼 Mk
            M = construct_personalization_masks(s, threshold)

            # 7. 初始化本地模型 wt_k
            u_prev = get_personalized_parameters(w_prev, M)
            v_prev = get_shared_parameters(w_prev, M)
            w_k = [M * u_prev, (1 - M) * v_prev]

            # 8. 對於每個本地週期 e 從 1 到 El
            for e in range(1, El + 1):
                # 9. 使用 Fk(w_k) 和正則化更新個性化參數 u_k
                u_k = update_personalized_parameters(w_k, D[k - 1], regularization=True)

                # 10. 使用 Fk(w_k) 和適應性約束更新共享參數 v_k
                v_k = update_shared_parameters(w_k, D[k - 1], adaptive_constraints=True)

            # 12. 計算本地模型更新 ∆wt_k = wt_k - wt−1_k
            delta_w_k = compute_local_update(w_k, w_prev)

            # 13. 使用 Eq. (12) 剪裁並添加噪聲以確保差分隱私
            delta_w_k_clipped = clip_and_add_noise(delta_w_k, epsilon, C)

            # 將本地更新添加到列表中
            local_updates.append(delta_w_k_clipped)

        # 15. 在區塊鏈網絡上聚合本地模型更新
        aggregate_updates_on_blockchain(local_updates)

        # 16. 更新全局模型 wt = wt−1 + (1/K) * sum(delta_w_k)
        w = update_global_model(w, local_updates, K)

        # 17. 將全局模型更新 wt 存儲到區塊鏈
        store_global_model_on_blockchain(w)

    # 19. 返回最終的全局模型 wEg
    return w
```

## Privacy Analysis

- **本地數據推斷**：對手可能試圖通過觀察相應聯邦學習客戶端共享的本地模型更新，推斷有關個人健康數據的敏感信息。我們的模型通過在與區塊鏈網絡共享本地模型更新之前應用差分隱私（DP）機制來減輕這一威脅。添加的噪聲提供了強大的隱私保證，確保共享的更新不會透露有關個人數據的敏感信息。
  
- **成員推斷攻擊**：對手可能試圖通過觀察模型的預測來判斷特定個人的數據是否包含在聯邦學習客戶端的訓練數據集中。我們的模型通過利用差分隱私的內在特性來應對這一威脅，這保證了模型的輸出不會顯著依賴於訓練集中的任何單個數據點的存在或缺失。


## Security Analysis

區塊鏈技術的整合增強了我們模型的安全性和聯邦學習過程的完整性。區塊鏈網絡提供的主要安全特性包括：

- **防篡改記錄**：區塊鏈在整個聯邦學習過程中維護所有本地和全局模型更新的不可變和可審計記錄。鏈中的每個區塊都以加密方式鏈接到前一個區塊，這使得對手在不被檢測的情況下篡改存儲數據在計算上變得不可行。這確保了模型更新的完整性和可追溯性。

- **共識機制**：區塊鏈網絡採用共識機制，例如工作量證明或權益證明，以驗證和批准新區塊的添加。共識機制確保網絡中的所有節點對區塊鏈的狀態達成一致，並防止惡意節點篡改數據或進行雙重支付。

- **加密安全性**：區塊鏈利用加密原語，例如數字簽名和哈希函數，以確保數據的真實性和完整性。數字簽名使得本地模型更新的來源和所有權驗證成為可能，同時，哈希函數提供對區塊數據的唯一且不可逆的表示，從而使檢測篡改嘗試變得簡單。

通過利用區塊鏈技術的安全特性，我們的模型確保了聯邦學習過程的完整性、可追溯性和真實性，防止了對共享模型更新的未經授權的修改和攻擊。


# 結論
作者提出了一個整合聯邦學習、差分隱私及區塊鏈技術的全新框架，用於BIoT系統中的安全健康數據分析。此框架的主要貢獻在於運用以太坊、Ganache、Web3.py及IPFS技術來確保數據安全、透明性及去中心化。

在SVHN數據集上的實驗結果顯示，作者的方法能有效實現一種安全且透明的機制，用於存儲及驗證模型更新。結合鏈上與鏈下存儲的混合存儲方案在交易延遲與Gas消耗指標上表現出高效且實用的特性。

所提出的框架解決了BIoT系統中數據隱私、安全及去中心化的挑戰，為安全且協同的數據分析提供了全面的解決方案。

## 未來方向
優化區塊鏈整合的可擴展性和效率，將框架擴展以支援異構架構，並探索其在不同醫療數據集與任務上的應用性。

