# 文章閱讀: PS-FedGAN: An Efficient Federated Learning Framework Based on Partially Shared Generative Adversarial Networks For Data Privacy

- 時間: 19 May 2023
- 作者: Achintha Wijesinghe, Songyang Zhang, Zhi Ding
- 原文連結: https://arxiv.org/abs/2305.11437

## 本文大綱
- 前言
- 介紹
    - 聯邦學習
    - 基於生成對抗網路方式的聯邦學習
    - 本文貢獻
- 方法和架構
- 理論結果
- 實驗
    - 效用評估
    - 隱私評估
    - 通訊成本評估
- 結論


---
# 前言
聯邦學習（Federated Learning, FL）因其在捕捉數據統計特徵的同時能夠保護數據隱私而成為一種有效的分佈式計算學習範式，看似優勢的學習模式卻可能因為FL客戶端之間存在實際數據異質性(e.g.數據分佈不均的情況下)，導致FL框架在捕捉本地客戶端數據的整體特徵屬性方面不足。

為了解決這一問題，有些人在FL中使用 GANs 來處理數據異質性，因為GANs可以集成於數據再生過程中，而不暴露原始數據。然而，現有的GAN相關FL框架常常面臨高通信成本和其他隱私問題，這限制了它們在現實情境中的應用。

為此，本研究提出了一個新的FL框架，僅需要部分GAN模型共享，命名為PS-FedGAN。這個新框架改進了GAN的發布和訓練機制，以應對客戶端之間異質數據分佈的問題，同時在降低通信成本的情況下增強隱私保護，尤其適用於無線網絡。作者的分析顯示，所提出的PS-FedGAN框架在收斂性和隱私保護方面具有明顯優勢。通過在多個知名基準數據集上的實驗結果，作者的PS-FedGAN框架顯示出在非獨立同分佈（non-IID）客戶端數據分佈下，能夠有效解決FL問題，同時保護數據隱私並降低通信開銷。


# 介紹
## 聯邦學習（Federated Learning, FL）
- 特色
    - 提供了一種分佈式和協作學習的框架
    - 保護用戶的數據隱私。 
- 挑戰
    - 數據分佈的異質性
    - 數據隱私考慮
    - 通信效率。
- 近年趨勢
    - 基於生成對抗網絡的方式

## 基於生成對抗網路方式的聯邦學習
- 特色: GANs 能夠再生數據統計而不需共享原始數據。
- 缺陷:
    - 隱私保護不力
        - 原因: 容易受到重建攻擊和成員推斷攻擊，攻擊者旨在再生數據樣本並檢查特定數據樣本的使用情況
        - 過往解決方案: 差分隱私（Differential Privacy, DP）
            >DP的主要缺點是隱私和實用性之間的權衡，其中引入了隱私預算來平衡性能和隱私。因此，為了利用下游任務的性能，通常選擇無限隱私預算，這樣就不提供隱私保護。
    - 由於完整模型或合成數據共享造成的通信冗餘
        - 因為共享模型的大小很大，許多現實網路場景中的通信資源有限。

## 本文貢獻
- 重新檢視了GAN共享策略在FL中的應用
- 提出了一種新的GAN發布機制，以應對用戶之間非獨立同分佈（non-IID）數據分佈的實際情況
    - 此框架在伺服器端重建了從本地客戶端訓練的部分共享GAN模型的分開生成器，其中每個用戶僅與其他用戶共享其鑑別器。
    - 顯著減少了模型共享的通信網絡開銷
    - 在通信回合中提供了更好的數據隱私
    - 彌合了實用性和隱私之間的差距


# 方法和架構
## Problem Setup
以下說明將以圖像分類為例。情境如下:

一個可靠的中央伺服器，其對客戶端訓練數據的訪問有限，並希望在全球任務中達到理想的準確度。假設客戶端之間存在 non-IID 的數據分佈以及脆弱的通信通道，例如: 為了給患者提供更好的服務，醫療界想透過訓練神經網路製作出一個能檢測特定疾病的模型。然而這需要多類型、豐富、完整的病人樣本，因此勢必向各地的醫院、診所索取來自患者的資料。

基於所有分佈式數據的全球模型可以有助於所有醫院在這樣的協作系統中，本地數據隱私是一個關鍵問題。此外，為了隱藏敏感信息而對數據集添加噪聲可能會導致不必要的信息失真或假象。因此，在本篇文章中，作者也探討如何在保護本地隱私的同時保留原始數據統計訊息。

## PS-FedGAN

### 模型假設
在作者提出的模型裡，假設系統中有一個位於雲端的中央伺服器和多個分佈式客戶端/用戶，這些客戶端與伺服器進行通信。每個客戶端擁有足夠的資源來訓練本地GAN模型。儘管應用了條件GAN（cGAN）來減少需要標籤檢測的需求，但作者提出的方案原則普遍適用於所有類型的生成模型。

為了評估作者提出的框架在保護隱私方面的有效性，考慮了存在對手攻擊者的情況。


![截圖 2024-08-10 上午11.18.50](https://hackmd.io/_uploads/HJdQ2IVcC.png)
![截圖 2024-08-10 上午11.31.38](https://hackmd.io/_uploads/ByLmkPV9A.png)


:::spoiler 圖1資訊: 展示了現有的完整GAN共享方法和PS-FedGAN在不可信通信通道中的區別。
- 模擬攻擊者的情形，作為評估PS-FedGAN隱私保護力的方式
- 假設攻擊者有能力竊聽連接本地用戶和伺服器的通信通道
- 攻擊者的目標是通過重建攻擊來估計本地用戶的數據分佈
- 在傳統的基於GAN的FL方法中，攻擊者將可以不受限制地訪問整個GAN模型。然而，PS-FedGAN專門設計用來解決完全共享GAN模型所帶來的安全漏洞
:::

### 組成

- 元素
    - 兩個生成器
        - $G_u$: 在本地用戶端訓練生成器
        - $G_s$: 在伺服器端訓練生成器
    - 公共判別器 $D_u$
        - 為了橋接(通過通信鏈路連接)這兩個生成器的訓練而共享的判別器
        - 僅在本地用戶端訓練。
### 機制
進行 User-server 通信過程，直到全球分類器（Cl）的單步更新。
>可參照圖2。
1. **本地訓練**：
    - 本地用戶首先開始訓練一個本地條件生成對抗網絡（cGAN），包括 $G_u$ 和判別器 $D_u$
    - 在本地用戶完成單次批次訓練後，訓練好的判別器 $D_u$ 被通過發布機制 $M_p$ 與伺服器共享
2. **發布機制**：
    - $M_p$ 表示發布機制，形式為 $M(D_u, z, l)$
        - $M$ : 發布機制(publishing mechanism)
        - $z$ : 是噪聲向量
        - $l$ : 是當前步驟中用於訓練 $G_u$  的假標籤。
3. **伺服器端更新**：
    - 在伺服器端，為每個用戶初始化一個單獨的生成器 $G_s$。
    - 每接收到一個用戶更新後，伺服器將 $G_s$ 更新一步。
    - 遵循PS-FedGAN算法1的指導方針
4. **合併與更新**：
    - 完成 N 次步驟後，我們使用來自每個 $G_s$ 生成的合成數據和伺服器可用的數據來更新全球分類器 $Cl$。
        - N 表示本地用戶的一個訓練周期，當用戶端更新N次後，即會更新全球模型Cl
    - 這個過程會繼續進行，直到 $Cl$ 收斂到所需的點。

![截圖 2024-08-10 中午12.14.27](https://hackmd.io/_uploads/rkyNtDV5A.png)
![截圖 2024-08-10 中午12.14.38](https://hackmd.io/_uploads/ryi4YPV50.png)

在完成本地用戶端的一個批次訓練後，訓練好的判別器Du通過PS-FedGAN發布機制Mp與伺服器共享。



### PS-FedGAN Publishing Mechanism $M_p$ 
- PS-FedGAN 的發布機制定義為 $M_p: M(D_u, z_t, l_t)$
    - 即每次訓練 $D_u$ 後，用戶端將 $D_u$、$z_t$ 和 $l_t$ 發送給伺服器。
    - $z_t$ 表示在用戶端第 t 步（或批次）用於訓練生成器 $G_u$ 的噪聲向量
    - $l_t$ 表示隨機標籤

### PS-FedGAN Local User Training
- $D_u$ 
    - 目的: 在初始化 $G_u$ 後於用戶端進行訓練。
    - 只要能達成目的，用戶端可以選擇任何架構來設計 $D_u$ 
- 訓練 $G_u$
    - 在本地，使用生成隨機向量 $z_t$ 和相應的隨機標籤 $l_t$  以進行訓練。
    - $D_u$ 中的隨機性以確定性 (deterministic manner) 方式處理，以便相應地訓練 GAN $G_u$
    - 接著，通過反向傳播（ backpropagation, BP）更新 $G_u$ 的參數。
- 保留 $G_u$ 的隨機性
    - 在反向傳播（BP）過程中更新 $D_u$ 的參數。
- 達成收斂要求
    - 進行多次 $D_u$ 的訓練。
- 最小化延遲
    - 在訓練 $G_u$ 之前，釋放 $M_p$ 給伺服器以最小化延遲。

### PS-FedGAN Server Training
伺服器端專用的生成器為 $G_s$，使用 secret seed 進行初始化。當接收到來自相應用戶的 $M_p$ 參數後，即使用來自相應用戶的 $z_t$ 和 $l_t$ 來對每個 $G_s$ 開始訓練過程，為了確保一致性並避免  $D_u$  中的隨機性，在訓練過程中使用與相應用戶相同的技術。此外，在訓練過程中，不需要等到所有其他用戶與伺服器通信完畢。

接下來，通過 $G_s$ 的參數進行反向傳播（BP），並根據需要更新這些參數。一旦收到來自所有用戶的更新，便進行全局分類器 $C_l$ 的更新。為了在每次迭代中更新$C_l$，會從每個 $G_s$ 生成固定數量的樣本，並將其與伺服器上可用的部分真實數據結合，進而創建包含多個用戶生成器的訓練樣本。

下方演算法1展示了 PS-FedGAN 訓練算法。

![截圖 2024-08-10 下午1.19.11](https://hackmd.io/_uploads/HJjIu_4qR.png)

## Attacker Models

對於攻擊者來說，要獲取訊息要從一開始就進行竊聽並確保沒錯過任何一輪通信；此外，必須獲得生成器的初始權重。然而，由於如功率、延遲和硬件能力等各種實際限制，這往往是不可能的。其中，生成器架構的多樣性、複雜性和變異性使得攻擊者準確推斷模型結構變得非常困難，進而在保護隱私方面發揮了重要作用。因此作者夠過利用複雜和變化多樣的生成器架構，使 PS-FedGAN 增加了一層額外的保護。

這個環節是為了評估 PS-FedGAN 在面對潛在攻擊者時的性能。在實驗裡，這些攻擊者被稱為 $A_R$。對於任何 M(θ)，攻擊者 $A_R$ 嘗試重建訓練樣本，假設 I 代表重建的樣本（本文件中的圖像），即：

$$
A_R : M(θ) \mapsto I.
$$

> $M(θ)$ 是PS-FedGAN 發布機制的簡化，$θ$ 代表所有參數


在作者的實驗中，考慮了兩種類型的攻擊者：$A_1$ 和 $A_2$，以及一個因子 r ( $r \in [0, 1]$ )。假設攻擊者 A1 和 A2 擁有相同的生成器 $G_u$ 的架構，以及每個深度學習網絡層中相同的權重和偏差項，但第一層除外( $w_1$ 和 $b_1$ 為 $G_u$ 的第 1 層權重和偏差項)。
- 對於 A1，設置第 1 層的權重 $w_{a1}$ 和偏差項 $b_{a11}$ 為 $w_{a11} = r w_1$ 和 $b_{a1} = b_1$
- 對於 A2，則設置第 1 層的權重不變為 $w_{a21} = w_1$，並將第 1 層的偏差設置為 $b_{a21} = r b_1$。

這兩個攻擊者對 $G_u$ 參數的了解與真實參數只有在第 1 層權重和偏差上有一個乘法因子 r 的輕微差異。

# 理論結果
## $Du$ 的收斂性

此小節展示了根據算法 1 訓練的兩個生成器和一個鑑別器的收斂性。

### 本地用戶（客戶端）
- 本地訓練的 GAN
    - 一個生成器 $G_u$，它捕捉了 $p_{gu}$ 的概率分佈
    - 一個鑑別器 $D_u$
- 本地用戶的數據分佈為 $p_{data}(x)$。
- 本地用戶使用 $z \sim p_z$ 訓練 $G_u$。


對於模型的收斂性，我們有以下特性。
### 命題與說明
**命題 1**：根據算法 1 訓練的兩個生成器  $G_u$ 和  $G_s$ 與共享的鑑別器 $D_u$ 會收斂到最優鑑別器 $D_u^*$，並且它唯一對應於給定的  $G_u$ ，即：

$$
D_u^* = \frac{p_{data}(x)}{p_{data}(x) + p_{gu}(x)}
$$

- 如果在沒有 $G_s$ 的情況下訓練，  $G_u$ 和 $D_u$，PS-FedGAN 中的 $D_u$ 會收斂到相同的鑑別器。也就是說，在雲端訓練 $G_s$ 不會影響本地 GAN 訓練的收斂性或性能。
- 如果在有 $G_s$ 的情況下訓練，則擁有一個唯一的 $D_u$。這一特性鞏固了 $G_s$ 收斂到 $G_u$ 的性質，這在關於生成器模型的以下命題中得到了描述。

## $G_u$ 和 $G_s$ 的收斂性

**命題 2** : 根據算法 1 使用共享的 $D_u$ 訓練的兩個生成器 $G_u$ 和 $G_s$ 將會收斂到一個唯一的 $G^* = G^*_u = G^*_s$，該模型能夠捕捉 $p_{data}$。

- 此命題確立了使用 PS-FedGAN 訓練的兩個分佈式生成器會收斂到相同的生成模型。
- 這個模型與通過經典 GAN 訓練所能獲得的最佳化模型相同。
- 無論是 $G_u$ 還是 $G_s$ 都能捕捉用戶端的數據分佈。

**命題 3.** 任何未能捕捉到 $G_u$ 或 $G_s$ 的權重和架構的生成器 $G_A$，無論是在初始狀態還是任何單一的通信回合中，都無法準確表徵數據分佈 $p_{data}$。

- 此命題提供了有關攻擊者所需能力的洞察。
- 為了攻擊所提出的模型，攻擊者需要使用從 $M_p$ 獲得的信息來預測生成器 G。然而，為了成功執行這種攻擊，攻擊者需要對生成器的架構和  $G_u$ 或 $G_s$  的初始權重擁有精確的了解，並且需要監控和捕捉每一輪通信。
 
在接下來的實驗部分，數值結果將證明這些要求的必要性，並進一步展示攻擊者在嘗試突破 PS-FedGAN 模型隱私時面臨的困難。

## $M_p$ 的差分隱私（differential privacy, DP）特性
- 鑑別器（discriminator）為 $D = f(\text{data})$
- 生成器（generator）為 $G = g(D, z)$
- $z$ 表示噪音。
### 背景說明
如果 $f(\text{data})$ 是差分隱私的，那麼 $g(f(D))$ 也是差分隱私的。因此，當 $D$ 是差分隱私的時候，生成器 $G$ 也是差分隱私的。此外，如果訓練過程基於原始數據，FL-GAN 會遵循差分隱私的要求。

在 PS-FedGAN 的實際場景中，受量化通道噪音影響的鑑別器 D  的模型被認為是差分隱私的，即鑑別器的權重 $W_D$ 是差分隱私的。由於攻擊者在提出的 PS-FedGAN 框架中只能在通訊回合期間獲取鑑別器 D 的訪問權限，因此由攻擊者從被入侵的 D 中重建的任何生成器 G 也是基於 $W_D$ 的差分隱私的。

**命題 4：** 任何由攻擊者重建的生成器 G 都應該在具有量化噪音或通道引起誤差的通訊通道中保持差分隱私。

> 這一命題表明，攻擊者估計的 GAN 模型在從客戶端到伺服器發送的原始模型權重 $W_D$ 上是差分隱私的。考慮共享模型與原始數據之間的 mutual information，我們有 \( I(\text{data}, W_D) \leq I(\text{data}, \text{data}) \)。因此，如果我們保護 \( W_D \) 中的隱私，我們也保護了部分原始數據的隱私。

**命題 5：** 與全數據共享相比，$M_p$ 保護了更多的隱私。


# 實驗

在本節展示了在非獨立同分佈 (non-IID) 使用者數據分佈下對 PS-FedGAN 的測試結果。

## 效用評估
### 實驗設計
此研究考慮了三種不同的異質用戶情境，且每個情境涉及總共 10 個用戶：

- **Split-1:** 在這個情況下，訓練數據被分成 10 個片段，每個片段包含來自單一類別的樣本。每個用戶被隨機分配一個不同的片段。
- **Split-2:** 在這個情況下，生成了 20 個訓練數據片段，每個片段包含來自單一類別的樣本。兩個片段隨機分配給每個用戶，且不重疊。
- **Split-3:** 在這個情況下，生成了 30 個片段，每個片段包含來自單一類別的樣本。三個片段隨機分配給每個用戶，且不重疊。

作為效用衡量標準，作者選擇了在監督設置下的全局模型的分類準確率，並將結果與幾種現有的 FL 替代方法進行比較：
- FedAvg (FA) 
- FedProx (FP) 
- SCAFFOLD (SD)
- Naivemix (NM) 
- FedMix (FM) 
- SDA-FL (SL)

作者還將部分共享的 PS-FedGAN (PS) 與完全共享的 GAN (FG) 作為性能基準進行比較。
### 實驗結果
:::spoiler 表1: 現有 FL 方法和完全 GAN 共享方法相較於 PS-FedGAN 在 Split-1 和 Split-2 中的分類準確率 (最佳)。

- 所提出的 PS-FedGAN 相較於大多數現有方法的優越性能，僅在完全共享 GAN (FG) 方法中略有落後。
    - PS-FedGAN 在通信成本和隱私損失上顯著降低，且達到和 FG 相似性能
        > DP 最大的問題就是隱私和效能擇一，但此框架似乎解決此問題
- SDA-FL 方法需要無限的隱私預算才能達到預期的效用，表示 SDA-FL 在平衡隱私和效用方面面臨重大挑戰。

> ps 其他替代方案在 Split-1 到 Split-3 提供了更多的真實數據給分類器，而 PS-FedGAN 在服務器上保持了固定量的真實數據 (1%)。Split-3 的類似結果見附錄。

![截圖 2024-08-10 下午2.09.03](https://hackmd.io/_uploads/B12WEYV9R.png)

:::



## 隱私評估
### 評估方法
- 使用 MNIST 數據集。
- 測量指標
    - 包括正規化均方誤差 (NMSE)
    - 結構相似性指數 (SSIM) 
    - 分類準確率
- 考慮了兩種不同的非獨立同分布 (non-IID) 使用者設置：
    - **Setup-1** 
        - 三個用戶: user1 擁有類別 {0,1}，user2 擁有類別 {2,3,4}，user3 擁有剩餘的類別 {5,6,7,8,9}。
        - 攻擊者模型: A1。
    - **Setup-2** 
        - 考慮了 10 個用戶
        - 數據劃分: Split-1
        - 攻擊者模型: A2 進行重建攻擊。

### 實驗結果



:::spoiler 分類準確率
### 實驗目的
表 2 顯示了不同 r 值下攻擊者對三位使用者的表現，其中這三個使用者的差別為類別數量。

### 實驗架構設定
- 假設攻擊者可以訪問由發布機制 $M_p$  釋放的所有元素。
- 假設攻擊者能夠準確猜測出確切的生成器架構。
- 在訓練開始時，生成器的權重對於 A1 (wa11 = rw1) 與之前提到的雲端生成器不同。
- 生成器在用戶、服務器和攻擊者處同時進行訓練。

選擇了一個在原始 MNIST 訓練集上訓練的攻擊分類器，並推斷攻擊者生成器生成的數據。這裡，攻擊者假設用戶使用的是 MNIST 數據。

### 實驗結果
- 隨著 r 值的增加，攻擊者獲得更好的準確率。
- 使用相同的攻擊分類器在雲端評估分類準確率，這反映了理想攻擊者的潛力以及雲端的效用。
- 具有一些初始權重差異的攻擊者只能表現得像隨機猜測一樣。
- user1 擁有 2 個類別，user2 擁有 3 個類別，而 user3 擁有 5 個類別。結果表明攻擊者必須獲得非常準確的架構和初始模型權重信息，才能達到更高推斷準確率。

![截圖 2024-08-10 下午2.20.46](https://hackmd.io/_uploads/rknTLKNq0.png)
:::


:::spoiler 針對重建圖像的分類準確率
### 目的
考慮 A2 對重建圖像的分類準確率。對於這個攻擊者，其生成器與雲端生成器的區別在於第一層的偏置項（ba21 = rb1）。在 Split-1 上評估了 A2 的表現。

### 圖3說明
- 隨著 r 的增加，攻擊的分類準確率有所提升。
- 與 A1 中的第一種類型的攻擊者類似，來自 A2 的攻擊者同樣需要非常精確的架構知識和初始權重。
- 這個測試案例進一步證明了 PS-FedGAN 在對抗分類攻擊方面的穩健性。

![截圖 2024-08-10 下午2.12.18](https://hackmd.io/_uploads/HyRT4tNc0.png)
:::


:::spoiler 重建質量與相似度
### 實驗原因
重建質量和相似度可以作為衡量隱私洩露的指標。故在表 3 比較了攻擊者與雲端生成的圖像之間的相似度。

### 實驗指標
- SSIM（結構相似性指數）和 NMSE（歸一化均方誤差），以 Setup-1 為基礎進行分析。

### 結果 
- 攻擊者生成的圖像無法捕捉到真實的數據分佈。
    - 攻擊者所達到的 NMSE 值很高，而 SSIM 值（最高為 1）非常低。

![截圖 2024-08-10 下午2.41.21](https://hackmd.io/_uploads/Hy09jFV5R.png)

### 觀察現象
如果攻擊者偏離了實際生成器的權重，其收斂結果將是一個平凡點。這意味著攻擊者無法捕捉到任何潛在的用戶數據特性，如圖 4 中的視覺示例所示。更多的結果和討論可在附錄中找到。


![截圖 2024-08-10 下午2.44.51](https://hackmd.io/_uploads/rJXO2FN90.png)

:::



## 通訊成本評估

### 實驗目的
表 4 展示了在每個通訊回合中，每個用戶與雲端伺服器之間需要共享的參數數量，分別對比了全共享 GAN 和 PS-FedGAN。

### 實驗結論
PS-FedGAN 相較於經典的全共享 GAN 節省了大量的通訊成本，這種優勢同樣適用於各種不同的 GAN 架構。

![截圖 2024-08-10 下午2.51.09](https://hackmd.io/_uploads/H1_yAt45C.png)



# 結論

在本研究中，基於 GAN 的聯邦學習框架 PS-FedGAN，相比現有的聯邦學習提案，在保護本地數據隱私和降低通信開銷方面具有顯著優勢。

PS-FedGAN 能夠實現與完全共享 GAN 架構相當的學習效用，同時顯著提升數據隱私保護並降低通信成本。實驗結果進一步展示了 PS-FedGAN 在對抗最先進的 GAN 基礎聯邦學習框架中的優越性能。這一 PS-FedGAN 原則和架構可以直接推廣以融入任何現有的 GAN。
