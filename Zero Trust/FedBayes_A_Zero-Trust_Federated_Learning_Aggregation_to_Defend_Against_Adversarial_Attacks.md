# 文章閱讀: FedBayes: A Zero-Trust Federated Learning Aggregation to Defend Against Adversarial Attacks

- 作者: Marc Vucovich, Devin Quinn, Kevin Choi, Christopher Redino, Abdul Rahman, Edward Bowen
- 時間: 4 Dec 2023 
- 連結: https://arxiv.org/abs/2312.04587
- Index Terms: federated learning, machine learning, adversarial attacks


---
聯邦學習看似解決原始數據集中處理帶來的威脅，卻仍有惡意參數誤導模型的隱患。本篇論文設計一個使用貝葉斯統計的模型，透過計算客戶端模型權重相對於先前模型權重的機率來減輕惡意客戶端的影響，並以實驗論證可行性。


# Introduction
聯邦學習的運作方式是通過初始化一個服務器來協調參與聯邦的客戶端的訓練，客戶端會在本地數據上訓練自己的模型，然後把新權重會發送回服務器，在服務器裡權重會被聚合形成新的全局模型。這個過程會重複幾輪。

當前主要的聚合方法是FedAvg的變體，將每個客戶端的權重平均在一起形成全局模型。然而，這些聚合方法特別容易受到對抗性攻擊，如 backdoor attacks、label flipping 和 weight attacks。本文提出 FedBayes，通過計算接收到的客戶端權重與先前全局模型權重之間的機率，來確保接收到的權重不會對聯邦有害。

對於全局模型的每一層，使用模型權重的平均值和標準差計算標準化分佈；通過累積分佈函數，計算每個客戶端權重的概率，這些權重是基於全局模型權重的累積分佈函數給出的。由於被投毒的權重預期會位於乾淨全局模型的正常分佈之外，因此具有較低機率的權重對聚合後的更新模型影響較小，這減少了惡意客戶端的影響。

# LITERATURE REVIEW
以下是過去學者對聯邦學習安全問題所提出的應對方法
## 基於性能的信任方法
- 解決方法
    - 試圖通過在中央服務器提供的乾淨數據集上進行評估來防禦對抗性攻擊
        - Zeno: 利用分布式隨機梯度下降（SGD）的方法，在每次迭代中，客戶端拉取最新的中央服務器模型，並使用本地抽樣的訓練數據估計梯度。該方法使用隨機零階預言機計算分數，對每次迭代中客戶端更新的可信度進行排名，並對具有最高分數的客戶端進行平均計算。
        - FLTrust: 利用在乾淨數據集上計算出的本地和服務器更新之間的 ReLU 裁剪餘弦相似性來啟動信任，並根據此為客戶端分配信任分數。
            - 如果本地模型更新的方向和幅度與服務器模型更新不一致，則該本地模型更新會獲得較低的信任分數。
            - 中央服務器根據信任分數對本地模型更新進行標準化，並作為全局模型更新。
- 問題
    - 過於仰賴足夠代表性的乾淨數據集。如果評估數據未能充分概括不同客戶端的數據，則良性客戶端的更新可能會與服務器更新在此不足的數據集上表現出差異，從而阻礙這些客戶端對系統的貢獻。反之，若評估數據集過於概括，可能導致惡意更新與服務器更新相差不大，使得被投毒的權重進入全局模型。
    - 對更新進行評分和加權的方法可能會錯誤地給予漏檢的惡意客戶端較高的權重，從而給被投毒的模型更大的影響力，無意中對系統造成權重攻擊。

## 基於機率的聚合方法
- 貝葉斯聚合方法
    - 實作方法
        - 使用 heterogeneous data 訓練 Bayesian models
        - 在服務器端，他們將每個客戶端的權重的高斯正態分布後驗進行相乘，以創建全局的高斯正態分布 -> 減少異質數據引起的聚合誤差
        - 在客戶端，他們提出了一種先驗迭代（PI）策略 -> 將來自服務器的全局後驗概率參數視為先驗
    - 目的
        - 處理異質數據
        - 通過 PI，從先驗分布中推導出本地訓練的先驗損失(prior loss)
        - 防止客戶端在訓練過程中偏離全局後驗(posterior)
    - 缺點
        - 依賴於客戶端使用 PI 來影響本地訓練會帶來客戶端腐蝕全局模型的風險
        - 客戶端或具有客戶端訪問權限的黑客容易篡改發送回服務器的結果
- FedProb 
    - 實作方法
        - 通過使用每個客戶端本地非獨立同分布（Non-IID）數據集的均值和協方差來計算每個客戶端的多變量正態分布的方法。訊息被發送到服務器後，即將數據集的分布進行平均，以創建全局分布。
        - 接著計算每個客戶端分布與全局分布之間的距離，以確定每個客戶端對新全局模型的影響程度。
    - 優點: 在非獨立同分布數據上能夠實現良好的性能，但也存在一些潛在的安全風險。
    - 風險
        - 黑客可能通過攔截提供的權重以及數據的均值和協方差來獲得客戶端數據的見解。


# 資料集
- Modified National Institute of Standards and Technology (MNIST)
- Canadian Institute for Advanced Research (CIFAR-10) 

# 方法
FedBayes 需與一個預訓練的模型一起使用，該模型由服務器發送給客戶端作為初始參數。這些初始參數將作為機率計算中的先驗，客戶端獲得初始參數後，將使用自己的數據繼續訓練模型，每個客戶端隨後將更新的參數發送回服務器。

在服務器端，算法會遍歷初始參數(先驗參數)的每一層，並計算該層權重的均值和標準差。利用全局均值和全局標準差計算全局正態分布，並創建全局累積分布函數（CDF），再基於先驗參數，通過全局 CDF 計算接收客戶端參數的累積機率。為此，需要將客戶端權重的 CDF 從先驗參數的 CDF 中減去。
> 先驗參數的均值和標準差將分別稱為全局均值 $\mu_{global}$ 和全局標準差 $\sigma_{global}$。

# 實驗設計

- 訓練數據集
    - 被劃分為 9 個子集。第一個子集被用來訓練 FL 設置中的初始預訓練模型，其餘 8 個數據子集用作 FL 設置中的 8 個客戶端。
        - 預訓練模型也用作基準，以顯示模型是否學習得當或被腐敗。
        - 每個客戶端擁有略微不同數量的每個類別的樣本，但它們都包含每個類別的樣本。
- FL 訓練包括 100 輪聚合，每輪有 5 次本地模型訓練。
- 調整了 FedAdam、FedAdagrad、FedYogi 的聚合超參數
- 在毒化數據集上進行實驗，且限制了毒化數據集的數量為 1 個客戶端。
    > 當超過 35% 的客戶端是惡意的時，FedBayes 無法阻止全球對抗效果。

實驗分為三個部分：

1. 基準性能：比較了 FedBayes 與 FedAvg、FedAdam、FedAdagrad 和 FedYogi 在使用乾淨數據進行訓練時的整體學習能力。
2. 後門攻擊：比較了上述聚合方法在客戶端執行後門攻擊時的表現。
3. 標籤翻轉：比較了上述聚合方法在客戶端執行標籤翻轉攻擊時的表現。

# 實驗結果
結果中展示的每個實驗都是以預訓練模型為起點。MNIST 預訓練模型在測試數據上的準確率約為 80%，而 CIFAR-10 預訓練模型在測試數據集上的準確率約為 60%。這些準確率將作為基準，來顯示 FL 模型是否正確學習或是否被惡意客戶端數據破壞。
## 基準性能
- 目的
    - 展示了 FedBayes 與標準 FL 聚合方法在使用乾淨數據時的性能比較。
- 結果
    - 左側圖表
        - 所有聚合方法的全球準確率（顯示在子圖的左側）按預期增加
    - 右側圖表
        - 準確率顯示客戶端 1 和客戶端 8 在每個訓練回合中都有所學習。
- 說明
    - FedBayes 能夠在正常的協作學習環境中與 FedAvg、FedAdam、FedAdagrad 和 FedYogi 一樣進行學習，並且可以替代這些聚合方法。

![截圖 2024-09-08 中午12.28.39](https://hackmd.io/_uploads/r1XZuic20.png)


## Backdoor Attacks

這個實驗對每個數據集進行了兩次。

- 第一次
    - 沒有使用權重攻擊: 每個客戶端向伺服器報告了正確的訓練數據量，所有客戶端的權重相等。
    - 分析
        - 在 MNIST 實驗中，這是一個較簡單的數據集，全球模型即使在有惡意客戶端的情況下也能清晰學習，迅速在測試集上達到 98% 的準確率，並在 100 輪訓練中保持穩定的性能。
        - 在 CIFAR-10 中，全球模型的最終準確率為 67%，比初始預訓練模型有所提高。
    - 結果
        - FedBayes 表現優於其他標準 FL 聚合方法。
        - ![截圖 2024-09-08 中午12.14.01](https://hackmd.io/_uploads/B1t5No52C.png)
- 第二次
    - 方法
        - 將後門攻擊與權重攻擊結合
        - 惡意客戶端 1 報告了使用兩倍數量的數據，以對全球模型產生更大影響。
    - 實驗原因: 後門攻擊與權重攻擊的結合對這些實驗的對抗性效果最為深遠
    - 實驗結果
        - 除了 FedBayes 之外，其他算法的性能下降更快，且完全不受權重影響。
        - 圖 A.2 中突出了 FedBayes 抵消這些影響的能力
![截圖 2024-09-08 中午12.22.48](https://hackmd.io/_uploads/ryBiUoq2R.png)




右側的圖表顯示了客戶端 1（紅色，惡意）和客戶端 8（藍色，良性）在前 50 輪訓練中的單個模型性能。這些結果強調了 FedBayes 保護聯邦中的良性客戶端免受惡意客戶端影響的能力，而其他算法顯示良性模型的準確率最終會下降，並趨向於惡意性能。

## Label Flipping
這個實驗對每個數據集進行了兩次。

- 第一次
    - 沒有使用權重攻擊
    - 結果![截圖 2024-09-08 中午12.22.36](https://hackmd.io/_uploads/H1qc8s9n0.png)
    - 結論: 其他方法的性能不穩定
- 第二次
    - 實驗方法: 將標籤翻轉與權重攻擊結合(3 倍的權重攻擊，即惡意客戶端 1 報告的數據量是實際擁有的三倍)
    - 結果: 其他聚合方法因為惡意客戶端對全球模型更新的影響而出現了更多的波動，而 FedBayes 在 100 輪訓練中達到了最強的性能並保持穩定 ![截圖 2024-09-08 中午12.27.00](https://hackmd.io/_uploads/ByGjPicn0.png)
    - 結論: FedBayes 比其他策略更容易學習並抵消對抗效應


總結，儘管引入標籤翻轉對手到聯邦中不會像在後門攻擊情境中那樣強迫良性客戶端的準確率下降並趨向於惡意水平，但標籤翻轉數據仍然可以擾亂過程並造成問題。

 

# 結論

實驗結果顯示，FedBayes 能夠有效保護參與聯邦的所有客戶端免受惡意客戶端的攻擊。此外，FedBayes 能夠像目前使用的標準 FL 聚合方法一樣進行學習，為客戶端提供了一種比傳統方法更安全的替代方案。FedBayes 在客戶端共同協作創建全球模型以保護重要資訊的情境中特別有用。例如，假設一群公司合作建立一個入侵偵測系統（IDS）來檢測進攻。如果在這種情境下，一個客戶端或一組客戶端將已知的攻擊標註為良性並用這些數據訓練其模型，則經過 FL 訓練後，全球模型可能會變得容易受到這些攻擊的威脅。使用 FedBayes，聯邦中的客戶端能夠更好地保護免受損壞數據的影響。

總體而言，FedBayes 是一種簡單的聚合技術，能夠在仍然從良性客戶端學習的同時，保護全球模型免受對抗性攻擊。
