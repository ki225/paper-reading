# Attack

paper
- [A Novel Data Poisoning Attack in Federated Learning based on Inverted Loss Function](https://www.sciencedirect.com/science/article/abs/pii/S0167404823001803)
- [Tracing Back the Malicious Clients in Poisoning Attacks to Federated Learning](https://arxiv.org/abs/2407.07221)
- [Data Poisoning Attack Based on Privacy Reasoning and Countermeasure in Federated Learning](https://ieeexplore.ieee.org/document/10566976)
- [Poisoning Web-Scale Training Datasets is Practical](https://arxiv.org/abs/2302.10149)

Github repo
- [Awesome Data Poisoning and Backdoor Attacks](https://github.com/penghui-yang/awesome-data-poisoning-and-backdoor-attacks)
